# -*- coding: utf-8 -*-
"""test_20180032.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12M8z-zFNAtsoHkirVqMrluPhjPq174SY
"""

import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
import torchvision.transforms as transforms

import matplotlib
import matplotlib.pyplot as plt
from matplotlib.pyplot import imshow

import os
import glob
from torch.utils.data import Dataset
from torchvision import transforms
import torchvision.transforms.functional as TF

# mount google drive
from google.colab import drive
drive.mount('/content/gdrive')
#!unzip /content/gdrive/MyDrive/2023_EEE4178_project/valid.zip
import subprocess
subprocess.run(["unzip", "/content/gdrive/MyDrive/2023_EEE4178_project/valid.zip"])

class MyDataset(Dataset):
    def __init__(self, npy_dir, label_dict=None):
        self.dir_path = npy_dir
        self.to_tensor = transforms.Compose([
            transforms.ToTensor(),
            transforms.Lambda(lambda x: x.transpose(0, 1)),
            transforms.Lambda(lambda x: TF.rotate(x, -90))
        ])
        self.npy_path = glob.glob(os.path.join(npy_dir, '*', '*.npy'))
        self.label_dict = label_dict or self.create_label_dict()

    def create_label_dict(self):
        label_dict = {}
        for path in self.npy_path:
            label_name = os.path.basename(os.path.dirname(path))
            if label_name not in label_dict:
                label_dict[label_name] = len(label_dict)
        return label_dict

    def __getitem__(self, index):
        single_data_path = self.npy_path[index]
        data = np.load(single_data_path, allow_pickle=True)

        image = data['image']
        image = self.to_tensor(image)
        image = TF.hflip(image)

        label_name = os.path.basename(os.path.dirname(single_data_path))
        label = self.label_dict[label_name]
        label = torch.tensor(label, dtype=torch.long)

        return (image, label)

    def __len__(self):
        return len(self.npy_path)

label_dict = {
    '30': 0, '31': 1, '32': 2, '33': 3, '34': 4, '35': 5, '36': 6, '37': 7, '38': 8, '39': 9,
    '41': 10, '42': 11, '43': 12, '44': 13, '45': 14, '46': 15, '47': 16, '48': 17, '49': 18,
    '4a': 19, '4b': 20, '4c': 21, '4d': 22, '4e': 23, '50': 24, '51': 25, '52': 26, '53': 27,
    '54': 28, '55': 29, '56': 30, '57': 31, '58': 32, '59': 33, '5a': 34, '61': 35, '62': 36,
    '64': 37, '65': 38, '66': 39, '67': 40, '68': 41, '69': 42, '6a': 43, '6d': 44, '6e': 45,
    '6f': 46, '71': 47, '72': 48, '74': 49, '75': 50, '79': 51,
}

# unzip 한 디렉토리 있는 path 그대로 넣어야, 디렉토리 옆 점 3개 누르면 '경로 복사' 있음 - 위의 사진 참조
valid_data = MyDataset("/content/valid", label_dict)

batch_size = 50
valid_loader = torch.utils.data.DataLoader(dataset=valid_data,
                                           batch_size=batch_size,
                                           shuffle=True)

# Device Configuration
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"device: {device}")

# Adjust Model Structure Depends on the Data
num_classes = 52  # 0~51 : 52 classes
in_channel = 1    # 흑백 이미지이니 in_channel은 1

# Hyper-parameters
learning_rate = 0.0001
num_epochs = 12

class ConvNet(nn.Module):
  def __init__(self, num_classes=52):
    super(ConvNet, self).__init__()

    self.layer1 = nn.Sequential(
        nn.Conv2d(1, 32, 5, 1, 2), # 1x100x100 --> 32x100x100
        nn.BatchNorm2d(32),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size=2) # 32x100x100 --> 32x50x50
    )
    self.layer2 = nn.Sequential( # 32x50x50 --> 64x50x50
        nn.Conv2d(32, 16, 1, 1, 0), # Bottleneck layer(차원 축소)
        nn.BatchNorm2d(16),
        nn.ReLU(),

        nn.Conv2d(16, 16, 5, 1, 2),
        nn.BatchNorm2d(16),
        nn.ReLU(),
        nn.Conv2d(16, 64, 1, 1, 0),
        nn.BatchNorm2d(64),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size=2) # 64x25x25
    )
    self.layer3 = nn.Sequential(
        nn.Conv2d(64, 32, 1, 1, 0),
        nn.BatchNorm2d(32),
        nn.ReLU(),

        nn.Conv2d(32, 32, 5, 1, 2),
        nn.BatchNorm2d(32),
        nn.ReLU(),
        nn.Conv2d(32, 128, 1, 1, 0),
        nn.BatchNorm2d(128),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size=5) # 128x5x5
    )
    self.fc1 = nn.Linear(128*5*5, 100)
    self.fc2 = nn.Linear(100, num_classes)

    self.dropout = nn.Dropout(0.4)

  def forward(self, x):
    x = self.layer1(x)
    x = self.layer2(x)
    x = self.layer3(x)
    x = x.reshape(x.size(0), -1)

    x = self.dropout(x)
    x = self.fc1(x)
    x = F.relu(x)
    x = self.dropout(x)
    x = self.fc2(x)
    x = F.relu(x)

    return x

test_model = ConvNet().to(device)

# 모델에 state_dict 로드
test_model.load_state_dict(torch.load('20180032.pth'))

# 모델을 평가 모드로 설정
test_model.eval() # Set model as evaluation mode

with torch.no_grad(): # auto_grad off
  correct = 0
  total = 0
  for images, labels in valid_loader:
    images = images.to(device)
    labels = labels.to(device)
    outputs = test_model(images)
    _, predicted = torch.max(outputs.data, 1)

    total += labels.size(0)
    correct += (predicted == labels).sum().item()

  print('Accuracy of the last_model network on the {} valid images: {} %'.format(len(valid_data), 100 * correct / len(valid_data)))